import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import json
import openai
import requests
from urllib.parse import urlparse
import time

# Page configuration MUST BE FIRST
st.set_page_config(
    page_title="India VC Intelligence",
    page_icon="ğŸš€",
    layout="wide"
)

# Version check
st.write("ğŸ§ª **VERSION: Enhanced Google with AI Filtering v4.0 - PROJECT OMEGA FOUNDATION**")

# Initialize APIs
try:
    openai.api_key = st.secrets["OPENAI_API_KEY"]
    from tavily import TavilyClient
    tavily_client = TavilyClient(api_key=st.secrets["TAVILY_API_KEY"])
except:
    st.error("API keys not found in secrets")

# Helper functions - DEFINED FIRST
def classify_query_category(query):
    """Classify search query into strategic categories"""
    query_lower = query.lower()
    if any(term in query_lower for term in ['thesis', 'philosophy', 'strategy']):
        return 'investment_thesis'
    elif any(term in query_lower for term in ['scaling', 'growth', 'framework']):
        return 'scaling_strategy'
    elif any(term in query_lower for term in ['market', 'trends', 'analysis']):
        return 'market_analysis'
    elif any(term in query_lower for term in ['sequoia', 'accel', 'matrix', 'elevation']):
        return 'thought_leadership'
    else:
        return 'general_intelligence'

def deduplicate_results(results):
    """Enhanced deduplication based on URL and title similarity"""
    unique_results = []
    seen_urls = set()
    seen_titles = set()
    
    for result in results:
        url = result.get('url', '')
        title = result.get('title', '').lower()
        
        # Skip if exact URL match
        if url in seen_urls:
            continue
            
        # Skip if very similar title
        title_words = set(title.split())
        is_similar = False
        for seen_title in seen_titles:
            seen_words = set(seen_title.split())
            if len(title_words & seen_words) / len(title_words | seen_words) > 0.8:
                is_similar = True
                break
        
        if not is_similar:
            unique_results.append(result)
            seen_urls.add(url)
            seen_titles.add(title)
    
    return unique_results

def generate_sample_data():
    """Generate sample dashboard data"""
    return {
        'total_articles': 1247,
        'high_priority': 89,
        'today_articles': 23,
        'avg_score': 72.4,
        'weekly_trend': [45, 52, 38, 67, 81, 73, 23],
        'sector_distribution': {
            'Fintech': 28,
            'SaaS': 22,
            'E-commerce': 18,
            'HealthTech': 12,
            'EdTech': 10,
            'Others': 10
        },
        'top_sources': {
            'TechCrunch': 156,
            'YourStory': 134,
            'Inc42': 98,
            'LinkedIn': 87,
            'Medium': 76
        }
    }

# Main title
st.title("ğŸš€ India VC Intelligence Agent")
st.subheader("ğŸ§  Enhanced AI-powered venture capital intelligence with strategic content discovery")

# DASHBOARD METRICS SECTION
st.markdown("---")
st.markdown("## ğŸ“Š Intelligence Dashboard")

# Generate sample data
dashboard_data = generate_sample_data()

# Dashboard metrics - 4 blue cards
col1, col2, col3, col4 = st.columns(4)

with col1:
    st.metric(
        label="ğŸ“„ Total Articles",
        value=f"{dashboard_data['total_articles']:,}",
        delta="+127 this week"
    )

with col2:
    st.metric(
        label="ğŸ¯ High Priority",
        value=dashboard_data['high_priority'],
        delta="+12 today"
    )

with col3:
    st.metric(
        label="ğŸ”¥ Today",
        value=dashboard_data['today_articles'],
        delta="+8 vs yesterday"
    )

with col4:
    st.metric(
        label="â­ Avg Score",
        value=f"{dashboard_data['avg_score']}/100",
        delta="+3.2 this week"
    )

# SIDEBAR FILTERS
st.sidebar.markdown("## ğŸ” Filters")

# Date range filter
date_range = st.sidebar.selectbox(
    "ğŸ“… Date Range",
    ["Last 24 hours", "Last 7 days", "Last 30 days", "Last 90 days", "Custom"]
)

# Sector filter
sectors = ["All Sectors", "Fintech", "SaaS", "E-commerce", "HealthTech", "EdTech", "Deep Tech", "Consumer Tech"]
selected_sector = st.sidebar.selectbox("ğŸ¢ Sector", sectors)

# VC firm filter
vc_firms = ["All Firms", "Sequoia Capital", "Accel", "Matrix Partners", "Elevation Capital", "Lightspeed", "Kalaari Capital"]
selected_vc = st.sidebar.selectbox("ğŸ’¼ VC Firm", vc_firms)

# Source quality filter
source_quality = st.sidebar.selectbox("ğŸ“° Source Quality", ["All Sources", "Premium Only", "Standard"])

# Score threshold
score_threshold = st.sidebar.slider("ğŸ¯ Min Relevance Score", 0, 100, 55)

# TABS INTERFACE
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ” Latest Content", "ğŸ“Š Analytics", "ğŸ¯ Themes", "ğŸ’¡ Insights"])

with tab1:
    st.markdown("### ğŸ” Latest Strategic Content")
    
    # Content discovery section
    col_left, col_right = st.columns([2, 1])
    
    with col_left:
        st.markdown("#### ğŸ§  Enhanced Strategic Content Discovery")
        st.info("**NEW:** 50+ targeted queries â€¢ Social media integration â€¢ Investment thesis hunting â€¢ 55+ relevance threshold")

        if st.button("ğŸ§  **RUN ENHANCED INTELLIGENT SEARCH**", type="primary", use_container_width=True):
            st.write("ğŸ§  **Starting Enhanced Multi-Source Intelligence Discovery**")
            
            # Test APIs
            st.write("### ğŸ”§ Testing Enhanced API Connections")
            
            try:
                st.write("ğŸ“¡ Testing Tavily API...")
                test_response = tavily_client.search(query="venture capital", max_results=1)
                st.success(f"âœ… Tavily connected! Enhanced search ready.")
                
                st.write("ğŸ§  Testing OpenAI API...")
                test_completion = openai.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[{"role": "user", "content": "Test"}],
                    max_tokens=5
                )
                st.success("âœ… OpenAI connected! Enhanced AI analysis ready.")
                
            except Exception as e:
                st.error(f"âŒ API connection failed: {str(e)}")
                st.stop()
            
            # ENHANCED STAGE 1: STRATEGIC MULTI-SOURCE SEARCH
            st.write("### ğŸ“¡ Enhanced Stage 1: Strategic Multi-Source Discovery")
            st.write("*Deploying 50+ targeted queries across strategic content sources...*")
            
            # MASSIVELY EXPANDED SEARCH QUERIES
            enhanced_queries = [
                # INVESTMENT THESIS & STRATEGY
                "venture capital investment thesis India",
                "VC investment strategy framework",
                "startup investment philosophy India",
                "venture capital market analysis India",
                "VC sector thesis fintech India",
                "investment strategy SaaS India",
                "venture capital outlook India 2025",
                "startup ecosystem trends India",
                
                # THOUGHT LEADERS BY NAME (some examples)
                "Shailendra Singh Sequoia Capital India",
                "Anandan Rajan Peak XV Partners",
                "Prashanth Prakash Accel India",
                "Avnish Bajaj Matrix Partners India",
                "Mukul Arora Elevation Capital",
                "Bejul Somaia Lightspeed India",
                "Karthik Reddy Blume Ventures",
                "Vani Kola Kalaari Capital",
                
                # SECTOR-SPECIFIC INTELLIGENCE
                "fintech investment trends India",
                "SaaS startup scaling India",
                "B2B marketplace strategy India",
                "edtech investment outlook India",
                "healthtech venture capital India",
                "logistics startup funding India",
                "enterprise software VC India",
                "consumer tech investment India",
                
                # SCALING & GROWTH FRAMEWORKS
                "startup scaling playbook India",
                "venture capital growth strategy",
                "startup business model India",
                "product market fit India",
                "go-to-market strategy India",
                "startup hiring strategy India",
                "venture building framework",
                "startup expansion strategy",
                
                # MARKET ANALYSIS & TRENDS
                "Indian startup market size",
                "venture capital market trends",
                "startup valuation trends India",
                "IPO readiness India startups",
                "startup exit strategy India",
                "venture capital LP trends",
                "startup funding winter India",
                "venture capital returns India",
                
                # GLOBAL VC PERSPECTIVES ON INDIA
                "Silicon Valley India venture capital",
                "global VC India investment",
                "international venture capital India",
                "cross-border venture capital India",
                "US VC India strategy",
                
                # OPERATIONAL EXCELLENCE
                "startup operations excellence",
                "venture capital due diligence",
                "startup board management",
                "venture capital portfolio management",
                "startup metrics framework",
                "venture capital value creation",
                
                # CONTRARIAN & EMERGING THEMES
                "contrarian venture capital India",
                "emerging technology VC India",
                "deep tech venture capital India",
                "climate tech investment India",
                "space tech venture capital India"
            ]
            
            st.info(f"ğŸ¯ **Enhanced Query Set:** {len(enhanced_queries)} strategic queries (vs 8 basic ones)")
            
            all_enhanced_results = []
            
            try:
                with st.expander("ğŸ” **Enhanced Stage 1 Progress** (Click to expand)", expanded=True):
                    # Show progress in batches
                    batch_size = 10
                    total_batches = (len(enhanced_queries) + batch_size - 1) // batch_size
                    
                    for batch_num in range(total_batches):
                        start_idx = batch_num * batch_size
                        end_idx = min(start_idx + batch_size, len(enhanced_queries))
                        batch_queries = enhanced_queries[start_idx:end_idx]
                        
                        st.write(f"**ğŸ” Batch {batch_num + 1}/{total_batches}:** Processing {len(batch_queries)} queries...")
                        
                        batch_progress = st.progress(0)
                        
                        for i, query in enumerate(batch_queries):
                            batch_progress.progress((i + 1) / len(batch_queries))
                            
                            try:
                                # Enhanced search with more results per query
                                response = tavily_client.search(query=query, max_results=3, days=90)  # Last 90 days
                                results = response.get('results', [])
                                
                                # Enhanced result processing
                                for result in results:
                                    # Extract enhanced metadata
                                    url = result.get('url', '')
                                    domain = urlparse(url).netloc if url else 'Unknown'
                                    
                                    # Source quality scoring
                                    premium_sources = [
                                        'techcrunch.com', 'a16z.com', 'sequoiacap.com', 'accel.com',
                                        'medium.com', 'substack.com', 'linkedin.com', 'twitter.com',
                                        'inc42.com', 'yourstory.com', 'entrackr.com', 'vccircle.com'
                                    ]
                                    
                                    source_quality = 'Premium' if any(ps in domain for ps in premium_sources) else 'Standard'
                                    
                                    enhanced_result = {
                                        'title': result.get('title', 'No title'),
                                        'content': result.get('content', 'No content'),
                                        'url': url,
                                        'domain': domain,
                                        'source_quality': source_quality,
                                        'published_date': result.get('published_date', datetime.now().isoformat()),
                                        'search_query': query,
                                        'search_category': classify_query_category(query)
                                    }
                                    
                                    all_enhanced_results.append(enhanced_result)
                                    
                            except Exception as e:
                                st.write(f"    âŒ Query '{query[:30]}...' failed: {str(e)[:50]}")
                        
                        # Small delay between batches to avoid rate limits
                        time.sleep(1)
                        
                        st.write(f"  âœ… Batch {batch_num + 1} complete!")
                
                st.success(f"ğŸ“Š **Enhanced Stage 1 Complete:** Found {len(all_enhanced_results)} total articles")
                
                # Enhanced deduplication
                unique_enhanced_results = deduplicate_results(all_enhanced_results)
                
                st.info(f"ğŸ“‹ **After enhanced deduplication:** {len(unique_enhanced_results)} unique articles")
                st.info(f"ğŸ† **Premium sources:** {len([r for r in unique_enhanced_results if r['source_quality'] == 'Premium'])} articles")
                
                if unique_enhanced_results:
                    # Show sample results
                    st.write("### ğŸ“‹ Sample Strategic Content Found:")
                    for i, article in enumerate(unique_enhanced_results[:5]):
                        quality_icon = "ğŸ†" if article['source_quality'] == 'Premium' else "ğŸ“„"
                        st.write(f"{i+1}. {quality_icon} **{article['title'][:80]}...**")
                        st.write(f"   ğŸ“‚ {article['search_category']} | ğŸŒ {article['domain']}")
                        st.write(f"   [ğŸ”— Read Article]({article['url']})")
                        st.write("---")
                else:
                    st.warning("No results found. Check API configuration.")
                    
            except Exception as e:
                st.error(f"âŒ **Enhanced search process failed:** {str(e)}")
    
    with col_right:
        st.markdown("#### ğŸ“ˆ Quick Stats")
        
        # Weekly trend chart
        fig_trend = go.Figure()
        fig_trend.add_trace(go.Scatter(
            x=list(range(7)),
            y=dashboard_data['weekly_trend'],
            mode='lines+markers',
            name='Articles Found',
            line=dict(color='#1f77b4', width=3)
        ))
        fig_trend.update_layout(
            title="ğŸ“ˆ Weekly Discovery Trend",
            xaxis_title="Days Ago",
            yaxis_title="Articles",
            height=300,
            showlegend=False
        )
        st.plotly_chart(fig_trend, use_container_width=True)
        
        # Recent activity
        st.markdown("#### ğŸ”” Recent Activity")
        st.write("ğŸ”¥ New fintech analysis from Sequoia")
        st.write("â­ Accel scaling playbook published")
        st.write("ğŸ¯ Matrix investment thesis update")
        st.write("ğŸ’¡ Lightspeed India market report")

with tab2:
    st.markdown("### ğŸ“Š Intelligence Analytics")
    
    col_left, col_right = st.columns(2)
    
    with col_left:
        # Sector distribution chart
        fig_sector = px.pie(
            values=list(dashboard_data['sector_distribution'].values()),
            names=list(dashboard_data['sector_distribution'].keys()),
            title="ğŸ¢ Content by Sector"
        )
        st.plotly_chart(fig_sector, use_container_width=True)
        
        # Quality score distribution
        sample_scores = [45, 52, 38, 67, 81, 73, 56, 89, 72, 64, 78, 55, 83, 69, 91]
        fig_scores = px.histogram(
            x=sample_scores,
            title="ğŸ¯ Quality Score Distribution",
            nbins=10
        )
        st.plotly_chart(fig_scores, use_container_width=True)
    
    with col_right:
        # Top sources chart
        fig_sources = px.bar(
            x=list(dashboard_data['top_sources'].values()),
            y=list(dashboard_data['top_sources'].keys()),
            title="ğŸ“° Top Content Sources",
            orientation='h'
        )
        st.plotly_chart(fig_sources, use_container_width=True)
        
        # Monthly trend
        months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun']
        monthly_data = [856, 924, 1124, 998, 1087, 1247]
        fig_monthly = px.line(
            x=months,
            y=monthly_data,
            title="ğŸ“ˆ Monthly Growth Trend",
            markers=True
        )
        st.plotly_chart(fig_monthly, use_container_width=True)

with tab3:
    st.markdown("### ğŸ¯ Emerging Themes")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### ğŸ”¥ Hot Topics")
        st.write("ğŸš€ **AI/ML Infrastructure** - 89% growth")
        st.write("ğŸ’³ **Fintech Consolidation** - 67% mentions")
        st.write("ğŸ¥ **Healthcare Tech** - 45% increase")
        st.write("ğŸŒ± **Climate Tech** - 156% surge")
        st.write("ğŸ“ **EdTech Evolution** - 34% discussion")
        
        st.markdown("#### ğŸ“‰ Declining Themes")
        st.write("ğŸ›’ E-commerce (-23%)")
        st.write("ğŸ® Gaming (-18%)")
        st.write("ğŸš— Mobility (-15%)")
    
    with col2:
        st.markdown("#### ğŸ’¡ Contrarian Opportunities")
        st.write("ğŸ” **B2B SaaS Consolidation** - Overlooked")
        st.write("ğŸ­ **Manufacturing Tech** - Underhyped")
        st.write("ğŸŒ¾ **AgriTech Scale** - Hidden potential")
        st.write("ğŸ  **PropTech Innovation** - Emerging")
        
        st.markdown("#### ğŸ¯ Investment Signals")
        st.write("ğŸ“ˆ Series A valuations stabilizing")
        st.write("ğŸ’° Growth stage getting competitive")
        st.write("ğŸŒ Cross-border deals increasing")
        st.write("ğŸ¤ Co-investment trends rising")

with tab4:
    st.markdown("### ğŸ’¡ Strategic Insights")
    
    st.markdown("#### ğŸ§  AI-Generated Intelligence Summary")
    
    insight_boxes = [
        {
            "title": "ğŸ¯ Market Timing",
            "content": "Current market conditions favor operational efficiency over growth-at-all-costs. VCs are prioritizing unit economics and path to profitability.",
            "confidence": "High (87%)"
        },
        {
            "title": "ğŸ¢ Sector Rotation", 
            "content": "Capital is shifting from consumer tech to B2B infrastructure. Developer tools and enterprise software seeing increased attention.",
            "confidence": "Medium (73%)"
        },
        {
            "title": "ğŸŒ Geographic Trends",
            "content": "Tier-2 city startups gaining VC attention. Infrastructure improvements enabling distributed teams and markets.",
            "confidence": "High (91%)"
        },
        {
            "title": "ğŸ’° Funding Patterns",
            "content": "Series A rounds taking longer but valuations stabilizing. Growth stage competition remains intense for quality assets.",
            "confidence": "High (89%)"
        }
    ]
    
    for insight in insight_boxes:
        with st.expander(f"**{insight['title']}** - {insight['confidence']}", expanded=True):
            st.write(insight['content'])
    
    st.markdown("#### ğŸ”® Predictive Signals")
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**ğŸ“ˆ Likely to Accelerate:**")
        st.write("â€¢ AI infrastructure startups")
        st.write("â€¢ Cross-border payment solutions") 
        st.write("â€¢ Developer productivity tools")
        st.write("â€¢ Climate tech solutions")
    
    with col2:
        st.markdown("**ğŸ“‰ Likely to Slow:**")
        st.write("â€¢ Pure consumer social apps")
        st.write("â€¢ Quick commerce expansion")
        st.write("â€¢ Generic B2C marketplaces")
        st.write("â€¢ High-burn growth models")

# Enhanced status section
st.markdown("---")
st.write("### ğŸ“Š Enhanced System Status")
st.success("**Enhanced Google with AI Filtering v4.0 ready!** 50+ strategic queries â€¢ Investment thesis hunting â€¢ 55+ relevance threshold â€¢ Premium source prioritization â€¢ Full dashboard interface")

# Footer
st.markdown("---")
st.markdown("ğŸ§  **Enhanced VC Intelligence** | Foundation for Project Omega | " + datetime.now().strftime("%Y-%m-%d %H:%M"))
